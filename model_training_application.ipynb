{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from time import time as time\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, jaccard_score\n",
    "import torchnet as tnt\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import notebook as tqdm\n",
    "\n",
    "from model_definitions import KrakonosNet as Net\n",
    "from imagery_handling import read_patch, classify_and_export\n",
    "\n",
    "# GLOBAL SETTINGS\n",
    "PlotSize = 12                                     # Size of plots\n",
    "matplotlib.rcParams['figure.figsize'] = [PlotSize*2, PlotSize]  \n",
    "CMAP = matplotlib.colors.ListedColormap(['black', 'white', 'orange'])               # Color mapping \n",
    "np.set_printoptions(precision=2, suppress=True)  # Array print precision\n",
    "\n",
    "# PATHS TO TRAIN/TEST DATA\n",
    "dataset_path = 'e:/datasets/test_unet/Krkonose2012/overlap'\n",
    "num_of_tiles = len(os.listdir(os.path.join(dataset_path, 'GT')))\n",
    "print(f'Number of tiles to be processed: \\n{num_of_tiles}\\n')\n",
    "\n",
    "# USE CIR, RGB, PAN DATA\n",
    "use_cir = False\n",
    "use_rgb = False\n",
    "use_pan = False\n",
    "\n",
    "# USE multi/hyperspectral DATA (first value is a boolen similar to use_rgb etc. and second value is the number of bands)\n",
    "use_mhs = (True, 6)\n",
    "print(f'Total number of bands used: \\n{use_cir*3 + use_rgb*3 + use_pan + use_mhs[0]*use_mhs[1]}')\n",
    "\n",
    "# MODEL NAME... USED AS FILENAME OF SAVED MODEL AND FOR APPROPRIATE RESULTS FOLDER\n",
    "model_name = 'U_Net'\n",
    "model_save_folder = os.path.join(dataset_path, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imagery(img_dir):\n",
    "    \"\"\"Reads the individual imagery patches and prepares them for \"\"\"\n",
    "    img_file_list = os.listdir(img_dir)\n",
    "    img_list = []\n",
    "        \n",
    "    for file in img_file_list:\n",
    "        img_patch = imageio.imread(os.path.join(img_dir, file)).astype(np.float32)\n",
    "        img_patch = img_patch[:,:,:].transpose([2,0,1])\n",
    "        img_patch = img_patch * 1/255\n",
    "            \n",
    "        img_list.append(img_patch)\n",
    "        del img_patch\n",
    "\n",
    "    img_features = np.stack(img_list, axis=0)\n",
    "    return img_features\n",
    "\n",
    "def read_patch(root_folder, cir, rgb, pan, mhs, gt=True):\n",
    "    \"\"\"Reads data from images as floats\"\"\"\n",
    "    \n",
    "    if cir:\n",
    "        cir_features = read_imagery(os.path.join(root_folder, 'CIR'))\n",
    "    if rgb:\n",
    "        rgb_features = read_imagery(os.path.join(root_folder, 'RGB'))\n",
    "    if mhs[0]:\n",
    "        mhs_features = read_imagery(os.path.join(root_folder, 'MHS'))\n",
    "\n",
    "    if pan:\n",
    "        pan_file_list = os.listdir(os.path.join(root_folder, 'PAN'))\n",
    "        pan_list = []\n",
    "        for file in pan_file_list:\n",
    "            pan_patch = imageio.imread(os.path.join(root_folder, 'PAN', file)).astype(np.float32)\n",
    "            pan_patch = pan_patch * 1/255\n",
    "            pan_patch = np.expand_dims(pan_patch, axis=0)\n",
    "            pan_list.append(pan_patch)\n",
    "            del pan_patch\n",
    "        pan_features = np.stack(pan_list, axis=0)\n",
    "\n",
    "\n",
    "    if cir and rgb:\n",
    "        features = np.concatenate([cir_features, rgb_features], axis=1)\n",
    "    elif cir:\n",
    "        features = cir_features\n",
    "    elif rgb:\n",
    "        features = rgb_features\n",
    "    elif pan:\n",
    "        features = pan_features\n",
    "    elif mhs:\n",
    "        features = mhs_features\n",
    "    else:\n",
    "        print('No valid data input.')\n",
    "    features = torch.from_numpy(features)\n",
    "    \n",
    "    \n",
    "    if gt:\n",
    "        gt_file_list = os.listdir(os.path.join(root_folder, 'GT'))\n",
    "        gt_list = []\n",
    "\n",
    "        for file in gt_file_list:\n",
    "            gt_patch = imageio.imread(os.path.join(root_folder, 'GT', file)).astype(np.int64)\n",
    "            # assigns 0 to classes 3 and above\n",
    "            # gt_patch[gt_patch > 2] = 0\n",
    "            \n",
    "            gt_list.append(gt_patch[:,:])\n",
    "            del gt_patch\n",
    "\n",
    "        ground_truth = np.stack(gt_list, axis=0)\n",
    "        ground_truth = torch.from_numpy(ground_truth)\n",
    "    \n",
    "    if gt:\n",
    "        return features, ground_truth\n",
    "    else:\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### putting the dataset into the TensorDataset wrapper\n",
    "data_features, data_labels = read_patch(dataset_path, use_cir, use_rgb, use_pan, use_mhs)\n",
    "class_count_patch = [len(np.unique(data_labels[i,:,:])) for i in range(data_labels.shape[0])]\n",
    "\n",
    "print(f'Size of image data: \\n{data_features.shape}\\n')\n",
    "print(f'Size of reference data: \\n{data_labels.shape}\\n')\n",
    "\n",
    "dataset = tnt.dataset.TensorDataset([data_features, data_labels])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(data_labels, return_counts=True)\n",
    "print(f'Class labels: \\n{unique}\\n')\n",
    "print(f'Number of pixels in a class: \\n{counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(obs, g_t):\n",
    "    \"\"\"the data augmentation function, introduces random noise and rotation\"\"\"\n",
    "    sigma, clip= 0.01, 0.03 \n",
    "    #Hint: use np.clip to clip and np.random.randn to generate gaussian noise\n",
    "    obs = obs + np.clip(sigma*np.random.randn(), -clip, clip).astype(np.float32).copy()\n",
    "\n",
    "    #random rotation 0 90 180 270 degree\n",
    "    n_turn = np.random.randint(4) #number of 90 degree turns, random int between 0 and 3\n",
    "    obs = np.rot90(obs, n_turn, axes=(2,3)).copy()\n",
    "    g_t = np.rot90(g_t, n_turn, axes=(1,2)).copy()\n",
    "\n",
    "    obs = torch.from_numpy(obs)\n",
    "    g_t = torch.from_numpy(g_t)\n",
    "    \n",
    "    return obs, g_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, args):\n",
    "    \"\"\"train for one epoch\"\"\"\n",
    "    model.train() #switch the model in training mode\n",
    "  \n",
    "    #the loader function will take care of the batching\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=args['batch_size'], sampler=args['train_subsampler'])\n",
    "    loader = tqdm.tqdm(loader, ncols=500)\n",
    "  \n",
    "    #will keep track of the loss\n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for index, (tiles, gt) in enumerate(loader):\n",
    "    \n",
    "        optimizer.zero_grad() #put gradient to zero\n",
    "        tiles, gt = augment(tiles, gt)\n",
    "    \n",
    "        pred = model(tiles.cuda()) #compute the prediction\n",
    "\n",
    "        loss = nn.functional.cross_entropy(pred.cpu(),gt, weight=torch.tensor(args['class_weights']))\n",
    "        loss.backward() #compute gradients\n",
    "\n",
    "        for p in model.parameters(): #we clip the gradient at norm 1\n",
    "            p.grad.data.clamp_(-1, 1) #this helps learning faster\n",
    "    \n",
    "        optimizer.step() #one SGD step\n",
    "        loss_meter.add(loss.item())\n",
    "        \n",
    "    return loss_meter.value()[0]\n",
    "\n",
    "def eval(model, sampler):\n",
    "    \"\"\"eval on test/validation set\"\"\"\n",
    "  \n",
    "    model.eval() #switch in eval mode\n",
    "  \n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=sampler)\n",
    "    loader = tqdm.tqdm(loader, ncols=500)\n",
    "  \n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (tiles, gt) in enumerate(loader):\n",
    "            pred = model(tiles.cuda())\n",
    "            loss = nn.functional.cross_entropy(pred.cpu(),gt)\n",
    "            loss_meter.add(loss.item())\n",
    "\n",
    "    return loss_meter.value()[0]\n",
    "\n",
    "\n",
    "def train_full(args):\n",
    "    \"\"\"The full training loop\"\"\"\n",
    "\n",
    "    #initialize the model\n",
    "    model = Net(args['n_channel'], args['conv_width'], args['dconv_width'], args['n_class'], args['cuda'])\n",
    "\n",
    "    print(f'Total number of parameters: {sum([p.numel() for p in model.parameters()])}')\n",
    "  \n",
    "    #define the Adam optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=args['scheduler_milestones'],\n",
    "                                               gamma=args['scheduler_gamma'])\n",
    "  \n",
    "    train_loss = np.empty(args['n_epoch'])\n",
    "    test_loss = np.empty(args['n_epoch']//args['n_epoch_test'] + 1)\n",
    "    test_i = 0\n",
    "\n",
    "    for i_epoch in range(args['n_epoch']):\n",
    "        #train one epoch\n",
    "        print(f'Epoch #{str(i_epoch+1)}')\n",
    "        train_loss[i_epoch] = train(model, optimizer, args)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Periodic testing on the validation set\n",
    "        if (i_epoch == args['n_epoch'] - 1) or ((i_epoch + 1) % args['n_epoch_test'] == 0):\n",
    "            print('Evaluation')\n",
    "            loss_test = eval(model, args['test_subsampler'])\n",
    "            test_loss[test_i] = loss_test\n",
    "            test_i += 1\n",
    "            \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1,1,1,ylim=(0,2), xlabel='Epoch #', ylabel='Loss')\n",
    "    plt.plot(range(args['n_epoch']), train_loss, label='Training loss')\n",
    "    test_epochs = list(range(args['n_epoch_test'], args['n_epoch'], args['n_epoch_test']))\n",
    "    test_epochs.append(args['n_epoch'])\n",
    "    plt.plot(test_epochs, test_loss, label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(train_loss)\n",
    "    print(test_loss)\n",
    "    args['loss_test'] = test_loss[-1]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = { #Dict to store all model parameters\n",
    "    'n_channel': use_cir*3 + use_rgb*3 + use_pan + use_mhs[0]*use_mhs[1],\n",
    "    'cuda': True,\n",
    "    'n_class': len(unique),\n",
    "    'conv_width': np.divide([64,64,128,128,256,256,512,512,1024,1024],        4).astype(np.int32),\n",
    "    'dconv_width': np.divide([1024,512,512,512,256,256,256,128,128,128,64,64], 4).astype(np.int32),\n",
    "    \n",
    "    'crossval_nfolds': 3,\n",
    "    'n_epoch_test': 2,          #periodicity of evaluation on test set\n",
    "    'scheduler_milestones': [60,80,95],\n",
    "    'scheduler_gamma': 0.3,\n",
    "    'class_weights': [0.1, 0.1, 0.8],\n",
    "\n",
    "    'n_epoch': 3,\n",
    "    'lr': 5e-4,\n",
    "    'batch_size': 1,\n",
    "}\n",
    "\n",
    "print(f'''Number of models to be trained:\n",
    "    {args['crossval_nfolds']}\n",
    "Number of spectral channels:\n",
    "    {args['n_channel']}\n",
    "Initial learning rate:\n",
    "    {args['lr']}\n",
    "Batch size:\n",
    "    {args['batch_size']}\n",
    "Number of training epochs:\n",
    "    {args['n_epoch']}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits = args['crossval_nfolds'], shuffle=True)\n",
    "trained_models = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset, class_count_patch)):\n",
    "    print(f'Training starts for model number {str(fold+1)}')\n",
    "    \n",
    "    a = time()\n",
    "    args['train_subsampler'] = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    args['test_subsampler'] = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    trained_models.append((train_full(args), args['loss_test']))\n",
    "    \n",
    "    state_dict_path = os.path.join(model_save_folder, f'fold_{str(fold)}.pt')\n",
    "    torch.save(trained_models[fold][0].state_dict(), state_dict_path)\n",
    "    print(f'Model saved to: {state_dict_path}')\n",
    "    print(f'Training finished in {str(time()-a)}s')\n",
    "    print('\\n\\n')\n",
    "\n",
    "print(f'Resulting loss for individual folds: \\n{[i for _, i in trained_models]}')\n",
    "print(f'Mean loss across all folds: \\n{np.mean([i for _, i in trained_models])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rgb_cir_gt_pred(tile_index, data, gt, model, cir, rgb):\n",
    "    # Function to plot prediction vs ground truth\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(facecolor='white')\n",
    "\n",
    "    data = data[tile_index,:,:,:]\n",
    "    pred = model(data[None,:,:,:].cuda()).cpu().detach().numpy()\n",
    "    pred = pred[0,:,:,:].argmax(0).squeeze()\n",
    "    \n",
    "    unique, counts = np.unique(pred, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    \n",
    "    data = data.cpu().numpy()\n",
    "    \n",
    "    if cir and rgb:\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(data[:3].transpose([1,2,0]))\n",
    "        plt.title('NIR Red Green composite')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(data[-3:].transpose([1,2,0]))\n",
    "        plt.title('Red Green Blue composite')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(gt[tile_index,:,:], CMAP)\n",
    "        plt.title('GT Labels')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(pred, CMAP)\n",
    "        plt.title('Predicted Labels')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    elif cir or rgb:\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(data.transpose([1,2,0]))\n",
    "        if cir:\n",
    "            plt.title('NIR Red Green composite')\n",
    "        else:\n",
    "            plt.title('Red Green Blue composite')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(gt[tile_index,:,:], CMAP)\n",
    "        plt.title('GT Labels')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred, CMAP)\n",
    "        plt.title('Predicted Labels')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_ref_pred(tile_index, data, ref, model, vis_bands, vis_title='data'):\n",
    "    # Plotting\n",
    "    plt.figure(facecolor='white')\n",
    "\n",
    "    data = data[tile_index,:,:,:]\n",
    "    pred = model(data[None,:,:,:].cuda()).cpu().detach().numpy()\n",
    "    pred = pred[0,:,:,:].argmax(0).squeeze()\n",
    "    \n",
    "    unique, counts = np.unique(pred, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    \n",
    "    data = data.cpu().numpy()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(data[vis_bands].transpose([1,2,0]))\n",
    "    plt.title(vis_title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ref[tile_index,:,:], CMAP)\n",
    "    plt.title('Reference labels')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred, CMAP)\n",
    "    plt.title('Predicted Labels')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_tile = 7\n",
    "model_fold = 0\n",
    "\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    model = trained_models[model_fold][0]\n",
    "    \n",
    "if use_mhs:\n",
    "    plot_data_ref_pred(vis_tile, data_features, data_labels, model, [3,4,5], 'RGB composite')\n",
    "else:\n",
    "    plot_rgb_cir_gt_pred(vis_tile, data_features, data_labels, model, use_cir, use_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model, data):\n",
    "    \"\"\"eval on test/validation set\"\"\"\n",
    "  \n",
    "    model.eval() #switch in eval mode\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False, drop_last=False)\n",
    "    loader = tqdm.tqdm(loader, ncols=500)\n",
    "    \n",
    "    classified = np.empty_like(y_t.detach().numpy())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index, (tiles, gt) in enumerate(loader):\n",
    "            pred = model(tiles.cuda()).cpu().detach().numpy()\n",
    "            classified[index, :, :] = pred.squeeze().argmax(0)\n",
    "\n",
    "    return classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_t = data_labels\n",
    "\n",
    "a = time()\n",
    "Y_t = classify(model, dataset)\n",
    "b = time()\n",
    "print('Inferrence finished in ' + str(b-a) + ' s')\n",
    "\n",
    "Y_t_flat = Y_t.flatten()\n",
    "\n",
    "unique, counts = np.unique(Y_t_flat, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_class = 255 # class number representing the background class (used for validation)\n",
    "\n",
    "#deletes zeroes from the reference set if there is a background class\n",
    "Y_t_flat = Y_t_flat[y_t_flat != background_class]\n",
    "y_t_flat = y_t_flat[y_t_flat != background_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_flat = y_t.detach().numpy().flatten()\n",
    "\n",
    "unique, counts = np.unique(y_t_flat, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, f1_scores, _ = precision_recall_fscore_support(y_t_flat, Y_t_flat, zero_division=0)\n",
    "jaccard_index = jaccard_score(y_t_flat, Y_t_flat, average=None)\n",
    "overall_accuracy = accuracy_score(y_t_flat, Y_t_flat)\n",
    "mean_f1_score = sum(f1_scores)/len(f1_scores)\n",
    "mean_iou_score = sum(jaccard_index)/len(jaccard_index)\n",
    "\n",
    "print(f'precisions [%]:      {precisions*100}')\n",
    "print(f'recalls    [%]:      {recalls*100}')\n",
    "print(f'f1-scores  [%]:      {f1_scores*100}')\n",
    "print(f'IoU scores [%]:      {jaccard_index*100}')\n",
    "print('')\n",
    "print(f'overall accuracy:    {overall_accuracy:.2%}')\n",
    "print(f'mean f1 score:       {mean_f1_score:.2%}')\n",
    "print(f'mean IoU score:      {mean_iou_score:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reusing a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the state_dictionary\n",
    "state_dict_path = 'E:\\\\datasets\\\\test_unet\\\\Krkonose2012\\\\overlap\\\\models\\\\fold_2.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a model to state_dict_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save a trained model state_dictionary\n",
    "torch.save(trained_model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse a model at state_dict_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for model definition\n",
    "args = {} #stores the parameters\n",
    "args['n_class'] = 3\n",
    "args['n_channel'] = 6 # 6 if use_cir and use_rgb else 3\n",
    "args['conv_width'] =  np.divide([64,64,128,128,256,256,512,512,1024,1024],        4).astype(np.int32)\n",
    "args['dconv_width'] = np.divide([1024,512,512,512,256,256,256,128,128,128,64,64], 4).astype(np.int32)\n",
    "args['cuda'] = True\n",
    "\n",
    "# Load a trained model state_dictionary\n",
    "model = Net(args['n_channel'], args['conv_width'], args['dconv_width'], args['n_class'], args['cuda'])\n",
    "model.load_state_dict(torch.load(state_dict_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results\n",
    "Results are not georeferenced – use ArcPy_georeference_results.py for georeferencing and combining into a single raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'E:\\\\datasets\\\\test_unet\\\\Krkonose2012\\\\overlap'\n",
    "results_path = os.path.join(source_path, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = read_patch(source_path, use_cir, use_rgb, use_pan, use_mhs, gt=False)\n",
    "print(in_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_rgb:\n",
    "    filenames = os.listdir(os.path.join(source_path, 'RGB'))\n",
    "elif use_cir:\n",
    "    filenames = os.listdir(os.path.join(source_path, 'CIR'))\n",
    "elif use_pan:\n",
    "    filenames = os.listdir(os.path.join(source_path, 'PAN'))\n",
    "elif use_mhs[0]:\n",
    "    filenames = os.listdir(os.path.join(source_path, 'MHS'))\n",
    "else:\n",
    "    print('no input files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_export(model_b, in_features_b, results_path_b, fnames):\n",
    "    for i, patch in enumerate(fnames):\n",
    "        in_patch = in_features_b[i,:,:,:]\n",
    "        pred = model_b(in_patch[None,:,:,:].cuda()).cpu().detach().numpy()\n",
    "        pred = pred[0,:,:,:].argmax(0).squeeze()\n",
    "\n",
    "        imageio.imwrite(os.path.join(results_path_b, patch), pred.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_and_export(model, in_features, results_path, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
